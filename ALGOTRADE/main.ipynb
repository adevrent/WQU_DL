{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker          TSLA\n",
      "Date                \n",
      "2012-02-10  2.073333\n",
      "2012-02-13  2.099333\n",
      "2012-02-14  2.211333\n",
      "2012-02-15  2.240000\n",
      "2012-02-16  2.278667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (50,1) into shape (50,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdataloaders\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mNBEATS\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\ALGOTRADE\\NBEATS.py:193\u001b[0m\n\u001b[0;32m    190\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Create the dataloaders\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNBEATS_Data_Loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Check for GPU\u001b[39;00m\n\u001b[0;32m    196\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\ALGOTRADE\\dataloaders.py:71\u001b[0m, in \u001b[0;36mNBEATS_Data_Loader\u001b[1;34m(series, H, n, val_size, test_size, batch_size)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mNBEATS_Data_Loader\u001b[39m(series, H, n, val_size, test_size, batch_size):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    Parameters:\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    series (pd.Series): Univariate time series to convert to PyTorch tensor\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m    batch_size (int): Number of samples\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mfeaturize_series_NBEATS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     X_train, Y_train, X_val, Y_val, X_test, Y_test \u001b[38;5;241m=\u001b[39m train_val_test_split(X, Y, val_size, test_size)\n\u001b[0;32m     73\u001b[0m     train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m create_data_loaders(X_train, Y_train, X_val, Y_val, X_test, Y_test, batch_size)\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\ALGOTRADE\\dataloaders.py:20\u001b[0m, in \u001b[0;36mfeaturize_series_NBEATS\u001b[1;34m(series, H, n)\u001b[0m\n\u001b[0;32m     18\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_rows, H))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_rows):\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m series[i : i \u001b[38;5;241m+\u001b[39m H\u001b[38;5;241m*\u001b[39mn]\n\u001b[0;32m     21\u001b[0m     Y[i, :] \u001b[38;5;241m=\u001b[39m series[i \u001b[38;5;241m+\u001b[39m H\u001b[38;5;241m*\u001b[39mn : i \u001b[38;5;241m+\u001b[39m H\u001b[38;5;241m*\u001b[39mn \u001b[38;5;241m+\u001b[39m H]\n\u001b[0;32m     23\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (50,1) into shape (50,)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import dataloaders\n",
    "from NBEATS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atakan\\AppData\\Local\\Temp\\ipykernel_16800\\739752483.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(data_filepath, header=0, index_col='Timestamp', parse_dates=['Timestamp'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Open     High      Low    Close  Volume_(BTC)  \\\n",
      "Timestamp                                                               \n",
      "2019-01-01 00:00:00  3693.85  3698.79  3693.85  3698.00      5.491289   \n",
      "2019-01-01 00:01:00  3694.72  3694.72  3690.65  3690.65      9.500151   \n",
      "2019-01-01 00:02:00  3689.73  3689.73  3686.62  3686.62      0.965966   \n",
      "2019-01-01 00:03:00  3692.85  3692.85  3688.32  3692.35      0.296662   \n",
      "2019-01-01 00:04:00  3692.35  3692.35  3690.34  3690.34      0.111622   \n",
      "\n",
      "                     Volume_(Currency)  Weighted_Price  \n",
      "Timestamp                                               \n",
      "2019-01-01 00:00:00       20301.156505     3696.974936  \n",
      "2019-01-01 00:01:00       35080.265871     3692.600865  \n",
      "2019-01-01 00:02:00        3562.371230     3687.884698  \n",
      "2019-01-01 00:03:00        1095.220713     3691.813285  \n",
      "2019-01-01 00:04:00         412.065433     3691.614849  \n"
     ]
    }
   ],
   "source": [
    "data_filepath = r\"C:\\Users\\Atakan\\atakan_python\\WQU_DL\\ALGOTRADE\\static_files\\btc_1min.csv\"\n",
    "df = pd.read_csv(data_filepath, header=0, index_col='Timestamp', parse_dates=['Timestamp'])\n",
    "df.index = pd.to_datetime(df.index, unit='s')\n",
    "\n",
    "start_date = \"2019-01-01\"\n",
    "end_date = \"2023-03-31\"\n",
    "\n",
    "df = df.loc[start_date:end_date, :]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25541\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Atakan\\AppData\\Local\\Temp\\ipykernel_16800\\2367134223.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  series.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "series = df.loc[:, 'Close']\n",
    "series.head()\n",
    "\n",
    "# Get rid of NaN values\n",
    "num_nans = series.isna().sum()\n",
    "print(num_nans)\n",
    "\n",
    "series.fillna(method='ffill', inplace=True)\n",
    "num_nans = series.isna().sum()\n",
    "print(num_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Loss Functions ---\n",
    "def sMAPE_loss(forecast, target, eps=1e-6):\n",
    "    # sMAPE = 200/H * mean(|F - y| / (|F| + |y|))\n",
    "    numerator = torch.abs(forecast - target)\n",
    "    denominator = torch.abs(forecast) + torch.abs(target) + eps\n",
    "    return 200 * torch.mean(numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1024) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mtrain_NBEATS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\ALGOTRADE\\NBEATS.py:112\u001b[0m, in \u001b[0;36mtrain_NBEATS\u001b[1;34m(train_loader, val_loader, model, loss_func, optimizer, device, num_epochs, feature)\u001b[0m\n\u001b[0;32m    109\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)   \u001b[38;5;66;03m# shape: (batch_size, H)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 112\u001b[0m forecasts \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# forecast shape: (batch_size, H)\u001b[39;00m\n\u001b[0;32m    113\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(forecasts, targets)\n\u001b[0;32m    114\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\ALGOTRADE\\NBEATS.py:83\u001b[0m, in \u001b[0;36mNBEATS.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     79\u001b[0m residual \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stack \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstacks:\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# Process through stack\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     residual, stack_forecast \u001b[38;5;241m=\u001b[39m \u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Aggregate forecasts\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     forecast_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m stack_forecast\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Atakan\\atakan_python\\WQU_DL\\ALGOTRADE\\NBEATS.py:59\u001b[0m, in \u001b[0;36mNBEATSStack.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     57\u001b[0m     x_bc, x_fc \u001b[38;5;241m=\u001b[39m block(residual)\n\u001b[0;32m     58\u001b[0m     residual \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m-\u001b[39m x_bc  \u001b[38;5;66;03m# update residual using the blockâ€™s input\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     \u001b[43mx_fc_sum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_fc\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m residual, x_fc_sum\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (1024) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "M = 3 # Number of stacks in the network\n",
    "K = 30  # Number of blocks in the stack\n",
    "H = 10  # Forecast horizon\n",
    "n = 5  # Look back n times the forecast horizon\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader, val_loader, test_loader = dataloaders.NBEATS_Data_Loader(series, H, n, val_size=0.2, test_size=0.1, batch_size=1024)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "# Initialize model\n",
    "model = NBEATS(M, K, H, n).to(device)\n",
    "\n",
    "# Choose loss function and optimizer\n",
    "loss_func = sMAPE_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_NBEATS(train_loader, val_loader, model, loss_func, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
